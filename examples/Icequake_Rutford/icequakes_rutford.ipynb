{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuakeMigrate example - Icequake detection at the Rutford Ice Stream, Antarctica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains an example demonstrating how to run QuakeMigrate for icequake detection.\n",
    "\n",
    "Here, we detail how to:\n",
    "\n",
    "1. Calculate a travel-time lookup table for the seismometer network and example grid, using a velocity model with homogeneous P- and S-wave velocities.\n",
    "2. Run the detect stage, to continuously migrate and stack phase arrival onset functions at each point in the grid, searching for coherent sources of energy in space and time.\n",
    "3. Run the trigger stage to identify candidate events from the continuous detect output.\n",
    "4. Run the locate stage to calculate refined locations for these candidate events, and provide a range of additional outputs and plots, including robust location uncertainty estimates and phase picks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "from obspy import UTCDateTime\n",
    "from obspy.clients.fdsn.mass_downloader import (\n",
    "    GlobalDomain,\n",
    "    Restrictions,\n",
    "    MassDownloader,\n",
    ")\n",
    "from obspy.core import AttribDict\n",
    "from pyproj import Proj\n",
    "\n",
    "from quakemigrate import QuakeScan, Trigger\n",
    "from quakemigrate.io import Archive, read_stations\n",
    "from quakemigrate.lut import compute_traveltimes\n",
    "from quakemigrate.signal.onsets import STALTAOnset\n",
    "from quakemigrate.signal.pickers import GaussianPicker\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- i/o paths ---\n",
    "station_file = \"./inputs/rutford_stations.txt\"\n",
    "data_in = \"./inputs/mSEED\"\n",
    "lut_out = \"./outputs/lut/icequake.LUT\"\n",
    "run_path = \"./outputs/runs\"\n",
    "run_name = \"example_run\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Download miniSEED data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = pathlib.Path(data_in)\n",
    "stationxml_storage = \"./inputs/DATALESS\"\n",
    "\n",
    "\n",
    "# --- Define directory structure for storing waveform data ---\n",
    "def get_mseed_storage(network, station, location, channel, starttime, endtime):\n",
    "    fname = (\n",
    "        data_path\n",
    "        / f\"{starttime.year}\"\n",
    "        / f\"{starttime.julday:03d}\"\n",
    "        / f\"{station}_{channel[2]}.m\"\n",
    "    ).as_posix()\n",
    "\n",
    "    return fname\n",
    "\n",
    "\n",
    "# --- Set network code & client ---\n",
    "network = \"YG\"\n",
    "datacentres = [\"IRIS\"]\n",
    "# global domain (specifying network and stations instead)\n",
    "domain = GlobalDomain()\n",
    "\n",
    "# --- Set time period over which download data ---\n",
    "starttime = UTCDateTime(\"2009-01-21T04:00:00.0\")\n",
    "endtime = UTCDateTime(\"2009-01-21T04:00:20.0\")\n",
    "\n",
    "# --- Read in station file ---\n",
    "stations = read_stations(station_file)\n",
    "stations_string = \",\".join(stations[\"Name\"])\n",
    "\n",
    "# --- Set up request ---\n",
    "restrictions = Restrictions(\n",
    "    starttime=starttime,\n",
    "    endtime=endtime,\n",
    "    chunklength_in_sec=86400,\n",
    "    network=network,\n",
    "    station=stations_string,\n",
    "    channel_priorities=[\"GL[123]\"],\n",
    "    minimum_interstation_distance_in_m=0,\n",
    ")\n",
    "\n",
    "# --- Download waveform data ---\n",
    "mdl = MassDownloader(providers=datacentres)\n",
    "mdl.download(\n",
    "    domain,\n",
    "    restrictions,\n",
    "    threads_per_client=3,\n",
    "    mseed_storage=get_mseed_storage,\n",
    "    stationxml_storage=stationxml_storage,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Calculate a travel-time lookup table (LUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: You may find that your system cannot run this example at the intended resolution. If so, you should adjust the node spacing, with the caveat that this will reduce the resolution of the final event location! This can be done either when the lookup table is created (i.e., adjust the line `grid_spec.node_spacing = [0.025, 0.025, 0.025]` to use larger node spacings, e.g., `0.05` or `0.1`) or by decimating this lookup table before the detect/locate stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Read in the station information file ---\n",
    "stations = read_stations(station_file)\n",
    "\n",
    "# --- Define the input and grid projections ---\n",
    "gproj = Proj(\n",
    "    proj=\"lcc\",\n",
    "    units=\"km\",\n",
    "    lon_0=-83.925,\n",
    "    lat_0=-78.145,\n",
    "    lat_1=-78.16,\n",
    "    lat_2=-78.13,\n",
    "    datum=\"WGS84\",\n",
    "    ellps=\"WGS84\",\n",
    "    no_defs=True,\n",
    ")\n",
    "cproj = Proj(proj=\"longlat\", datum=\"WGS84\", ellps=\"WGS84\", no_defs=True)\n",
    "\n",
    "# --- Define the grid specifications ---\n",
    "# AttribDict behaves like a Python dict, but also has '.'-style access.\n",
    "grid_spec = AttribDict()\n",
    "grid_spec.ll_corner = [-84.1, -78.17, 1.0]\n",
    "grid_spec.ur_corner = [-83.75, -78.12, 3.0]\n",
    "grid_spec.node_spacing = [0.025, 0.025, 0.025]\n",
    "grid_spec.grid_proj = gproj\n",
    "grid_spec.coord_proj = cproj\n",
    "\n",
    "# --- Homogeneous LUT generation ---\n",
    "lut = compute_traveltimes(\n",
    "    grid_spec,\n",
    "    stations,\n",
    "    method=\"homogeneous\",\n",
    "    phases=[\"P\", \"S\"],\n",
    "    vp=3.841,\n",
    "    vs=1.970,\n",
    "    log=True,\n",
    "    save_file=lut_out,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run the detect stage: continuously migrate phase arrival onset functions through the grid to detect coalescence peaks in space and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Read in station file ---\n",
    "stations = read_stations(station_file)\n",
    "\n",
    "# --- Create new Archive and set path structure ---\n",
    "archive = Archive(\n",
    "    archive_path=data_in, stations=stations, archive_format=\"YEAR/JD/STATION\"\n",
    ")\n",
    "\n",
    "# --- Create new Onset ---\n",
    "onset = STALTAOnset(position=\"classic\", sampling_rate=250)\n",
    "onset.phases = [\"P\", \"S\"]\n",
    "onset.bandpass_filters = {\"P\": [20, 124, 4], \"S\": [10, 124, 4]}\n",
    "onset.sta_lta_windows = {\"P\": [0.01, 0.25], \"S\": [0.05, 0.5]}\n",
    "onset.channel_maps = {\"P\": \"*1\", \"S\": \"*[2,3]\"}\n",
    "\n",
    "# --- Decimate the LUT by a factor of 2 in each dimension, if needed ---\n",
    "# lut = lut.decimate([2, 2, 2,])\n",
    "\n",
    "# --- Create new QuakeScan ---\n",
    "scan = QuakeScan(\n",
    "    archive,\n",
    "    lut,\n",
    "    onset=onset,\n",
    "    run_path=run_path,\n",
    "    run_name=run_name,\n",
    "    log=True,\n",
    "    loglevel=\"info\",\n",
    ")\n",
    "\n",
    "# --- Set detect parameters ---\n",
    "scan.timestep = 1.0\n",
    "# NOTE: please increase the thread-count as your system allows; the\n",
    "# core migration routines are compiled against OpenMP, and using\n",
    "# multithreading will ~ linearly speed up the compute time!\n",
    "scan.threads = 1\n",
    "\n",
    "# --- Set time period over which to run detect ---\n",
    "starttime = \"2009-01-21T04:00:05.0\"\n",
    "endtime = \"2009-01-21T04:00:10.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run detect ---\n",
    "scan.detect(starttime, endtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the trigger stage: identify individual icequakes from the continuous detect output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create new Trigger ---\n",
    "trig = Trigger(lut, run_path, run_name, log=True, loglevel=\"info\")\n",
    "\n",
    "# --- Set trigger parameters ---\n",
    "trig.marginal_window = 0.06\n",
    "trig.min_event_interval = 0.12\n",
    "trig.normalise_coalescence = True\n",
    "\n",
    "# --- Static threshold ---\n",
    "trig.threshold_method = \"static\"\n",
    "trig.static_threshold = 3.0\n",
    "\n",
    "# --- Run trigger ---\n",
    "trig.trigger(starttime, endtime, interactive_plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the trigger summary PDF file\n",
    "NOTE: this may not display properly for some OS's / browsers (e.g. Safari on MacOS). If all you see is a grey box, please try opening the notebook in Chrome or Firefox, or open the file directly using a PDF viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the trigger summary pdf file\n",
    "icequake_trigger_summary_image_fname = \"outputs/runs/icequake_example/trigger/summaries/icequake_example_2009_021_Trigger.pdf\"\n",
    "from IPython.display import IFrame  # For plotting pdf\n",
    "\n",
    "IFrame(icequake_trigger_summary_image_fname, width=800, height=450)  # Plot pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run the locate stage: calculate refined locations and location uncertainty estimates\n",
    "\n",
    "Note: Here we create a new onset object, using the \"centred\" STALTAOnset. This produces a more accurate gaussian representation of the phase arrival probability density function, and is less phase-shifted. However, it is much more sensitive to sharp offsets due to instrument spikes etc., and is less flexible in identifying arrivals with different frequency content than the \"classic\" STALTAOnset, so in general that is the better choice to use for detect()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create new Onset ---\n",
    "onset = STALTAOnset(position=\"centred\", sampling_rate=250)\n",
    "onset.phases = [\"P\", \"S\"]\n",
    "onset.bandpass_filters = {\"P\": [20, 124, 4], \"S\": [10, 124, 4]}\n",
    "onset.sta_lta_windows = {\"P\": [0.01, 0.25], \"S\": [0.05, 0.5]}\n",
    "onset.channel_maps = {\"P\": \"*1\", \"S\": \"*[2,3]\"}\n",
    "\n",
    "# --- Create new PhasePicker ---\n",
    "picker = GaussianPicker(onset=onset)\n",
    "picker.plot_picks = True\n",
    "\n",
    "# --- Create new QuakeScan ---\n",
    "scan = QuakeScan(\n",
    "    archive,\n",
    "    lut,\n",
    "    onset=onset,\n",
    "    picker=picker,\n",
    "    run_path=run_path,\n",
    "    run_name=run_name,\n",
    "    log=True,\n",
    "    loglevel=\"info\",\n",
    ")\n",
    "\n",
    "# --- Set locate parameters ---\n",
    "scan.marginal_window = 0.06\n",
    "# NOTE: please increase the thread-count as your system allows; the\n",
    "# core migration routines are compiled against OpenMP, and using\n",
    "# multithreading will ~ linearly speed up the compute time!\n",
    "scan.threads = 1\n",
    "\n",
    "# Turn on plotting features\n",
    "scan.plot_event_summary = True\n",
    "\n",
    "# --- Toggle writing of waveforms ---\n",
    "scan.write_cut_waveforms = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run locate ---\n",
    "scan.locate(starttime=starttime, endtime=endtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Some of the key locate outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the .event file, containing event origin time and location:\n",
    "icequake_event_fname = (\n",
    "    \"./outputs/runs/example_run/locate/events/20090121040007144.event\"\n",
    ")\n",
    "event_df = pd.read_csv(icequake_event_fname)\n",
    "\n",
    "event_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the .picks file, containing station time picks:\n",
    "icequake_pick_fname = (\n",
    "    \"outputs/runs/example_run/locate/picks/20090121040007144.picks\"\n",
    ")\n",
    "pick_df = pd.read_csv(icequake_pick_fname)\n",
    "\n",
    "pick_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the event summary pdf file, containing event origin time and location, a\n",
    "# plot displaying the 3D coalescence image, and a waveform gather showing the\n",
    "# fit of the modelled arrival times to the data:\n",
    "icequake_event_summary_image_fname = \"outputs/runs/example_run/locate/summaries/example_run_20090121040007144_EventSummary.pdf\"\n",
    "from IPython.display import IFrame  # For plotting pdf\n",
    "\n",
    "IFrame(icequake_event_summary_image_fname, width=800, height=550)  # Plot pdf\n",
    "\n",
    "# NOTE: this may not display properly for some OS's / browsers (e.g. Safari on\n",
    "# MacOS). If all you see is a grey box, please try opening the notebook in\n",
    "# Chrome or Firefox, or open the file directly using a PDF viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show an example of a pick summary pdf file, displaying the onset functions\n",
    "# for P and S phases, the gaussian fit to the onset function within the pick\n",
    "# window, and the resulting picktime, uncertainty and SNR.\n",
    "icequake_event_summary_image_fname = \"outputs/runs/example_run/locate/pick_plots/20090121040007144/20090121040007144_ST10.pdf\"\n",
    "from IPython.display import IFrame  # For plotting pdf\n",
    "\n",
    "IFrame(icequake_event_summary_image_fname, width=800, height=550)  # Plot pdf\n",
    "\n",
    "# NOTE: this may not display properly for some OS's / browsers (e.g. Safari on\n",
    "# MacOS). If all you see is a grey box, please try opening the notebook in\n",
    "# Chrome or Firefox, or open the file directly using a PDF viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
